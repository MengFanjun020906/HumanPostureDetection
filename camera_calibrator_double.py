#!/usr/bin/env python3
"""
åŒç›®æ‘„åƒå¤´æ ‡å®šå·¥å…· - ä¸“ä¸šä¼˜åŒ–ç‰ˆ
================================================
ç‰¹ç‚¹:
- é²æ£’å›¾åƒé…å¯¹ (åŸºäºæ–‡ä»¶ååºå·)
- æ·±åº¦ä¼˜åŒ–çš„ç«‹ä½“æ ¡æ­£ (alphaå‚æ•°æ§åˆ¶)
- å…¨é¢çš„è´¨é‡éªŒè¯ (æçº¿è¯¯å·®/ç‰©ç†å‚æ•°)
- ç”Ÿäº§çº§ç»“æœä¿å­˜ (XML+YAML)
- ç¯®çƒç»•æ†åœºæ™¯ä¸“å±éªŒè¯

ä½¿ç”¨è¯´æ˜:
1. å‡†å¤‡åŒæ­¥é‡‡é›†çš„å·¦å³ç›¸æœºå›¾åƒ (å‘½åå¦‚ left_001.jpg, right_001.jpg)
2. è°ƒæ•´ chessboard_size å’Œ square_size åŒ¹é…ä½ çš„æ ‡å®šæ¿
3. è¿è¡Œ: python stereo_calibrator.py
4. æŒ‰ä»»æ„é”®ç»§ç»­æ¯å¼ å›¾åƒçš„æ£€æµ‹
"""

import numpy as np
import cv2
import glob
import os
import re
import yaml
from pathlib import Path
import argparse
import matplotlib.pyplot as plt
from datetime import datetime
from PIL import Image, ImageDraw, ImageFont


def put_text_cn(img, text, org, color=(0, 255, 0), font_size=28, font_path=None):
    """åœ¨OpenCVå›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬ã€‚
    å‚æ•°:
        img: OpenCVå›¾åƒ(BGR)
        text: è¦ç»˜åˆ¶çš„ä¸­æ–‡å­—ç¬¦ä¸²
        org: å·¦ä¸Šè§’ä½ç½®(x, y)
        color: æ–‡æœ¬é¢œè‰²(BGR)
        font_size: å­—å·
        font_path: å­—ä½“è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨ Windows å¾®è½¯é›…é»‘
    è¿”å›:
        ç»˜åˆ¶åçš„å›¾åƒ
    """
    if font_path is None:
        # Windows å¸¸è§ä¸­æ–‡å­—ä½“
        font_path = "C:/Windows/Fonts/msyh.ttc"
        if not os.path.exists(font_path):
            # å…œåº•ï¼šå°è¯•å®‹ä½“
            alt = "C:/Windows/Fonts/simsun.ttc"
            if os.path.exists(alt):
                font_path = alt
            else:
                # æ— ä¸­æ–‡å­—ä½“æ—¶ï¼Œé€€åŒ–ä¸ºè‹±æ–‡ç»˜åˆ¶ï¼ˆä»ç„¶è¿”å›åŸå›¾ï¼‰
                cv2.putText(img, text, org, cv2.FONT_HERSHEY_SIMPLEX, font_size/32.0, color, 2, cv2.LINE_AA)
                return img

    # è½¬ä¸ºPILå›¾åƒè¿›è¡Œä¸­æ–‡ç»˜åˆ¶
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    try:
        font = ImageFont.truetype(font_path, font_size)
    except Exception:
        font = ImageFont.load_default()
    # PIL ä½¿ç”¨RGBé¢œè‰²
    rgb = (int(color[2]), int(color[1]), int(color[0]))
    draw.text((int(org[0]), int(org[1])), str(text), font=font, fill=rgb)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

def parse_args():
    parser = argparse.ArgumentParser(description='åŒç›®æ‘„åƒå¤´æ ‡å®šå·¥å…·')
    parser.add_argument('--left', default='left', help='å·¦ç›¸æœºå›¾åƒç›®å½•')
    parser.add_argument('--right', default='right', help='å³ç›¸æœºå›¾åƒç›®å½•')
    parser.add_argument('--size', default='9x6', help='æ£‹ç›˜æ ¼å†…è§’ç‚¹å°ºå¯¸ (å®½xé«˜)')
    parser.add_argument('--square', type=float, default=0.025, help='æ£‹ç›˜æ ¼æ–¹æ ¼å¤§å°(ç±³)')
    parser.add_argument('--alpha', type=float, default=0.8, help='ç«‹ä½“æ ¡æ­£alphaå‚æ•° (0.0-1.0)')
    parser.add_argument('--output', default='calibration_results_double', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--test', action='store_true', help='æ ‡å®šåç«‹å³æµ‹è¯•æ ¡æ­£æ•ˆæœ')
    return parser.parse_args()

def pair_images(left_dir, right_dir):
    """åŸºäºæ–‡ä»¶ååºå·æ™ºèƒ½é…å¯¹å›¾åƒ"""
    left_files = glob.glob(os.path.join(left_dir, '*.jpg')) + glob.glob(os.path.join(left_dir, '*.png'))
    right_files = glob.glob(os.path.join(right_dir, '*.jpg')) + glob.glob(os.path.join(right_dir, '*.png'))
    
    if not left_files or not right_files:
        raise ValueError(f"æœªæ‰¾åˆ°å›¾åƒ! æ£€æŸ¥ç›®å½•: left='{left_dir}', right='{right_dir}'")
    
    print(f"æ‰¾åˆ°å›¾åƒ: å·¦={len(left_files)}, å³={len(right_files)}")
    
    # æå–åºå· (æ”¯æŒå¤šç§å‘½åæ ¼å¼)
    def extract_index(filename):
        basename = os.path.basename(filename)
        # å°è¯•åŒ¹é…æ•°å­—åºå·
        match = re.search(r'(\d+)[^\d]*$', os.path.splitext(basename)[0])
        if match:
            return int(match.group(1))
        # å°è¯•åŒ¹é…æ—¶é—´æˆ³
        match = re.search(r'(\d{8}_\d{6})', basename)
        if match:
            return int(''.join(filter(str.isdigit, match.group(1))))
        return -1
    
    left_pairs = [(extract_index(f), f) for f in left_files]
    right_pairs = [(extract_index(f), f) for f in right_files]
    
    # è¿‡æ»¤æ— æ•ˆåºå·
    left_pairs = [(idx, f) for idx, f in left_pairs if idx != -1]
    right_pairs = [(idx, f) for idx, f in right_pairs if idx != -1]
    
    if not left_pairs or not right_pairs:
        raise ValueError("æ— æ³•ä»æ–‡ä»¶åæå–æœ‰æ•ˆåºå·! è¯·é‡å‘½åå›¾åƒä¸º left_001.jpg, right_001.jpg æ ¼å¼")
    
    # æŒ‰åºå·æ’åº
    left_pairs.sort(key=lambda x: x[0])
    right_pairs.sort(key=lambda x: x[0])
    
    # åˆ›å»ºå­—å…¸
    left_dict = {idx: f for idx, f in left_pairs}
    right_dict = {idx: f for idx, f in right_pairs}
    
    # æ‰¾å…±åŒåºå·
    common_indices = sorted(set(left_dict.keys()) & set(right_dict.keys()))
    paired_images = [(left_dict[i], right_dict[i]) for i in common_indices]
    
    print(f"æˆåŠŸé…å¯¹ {len(paired_images)} å¯¹å›¾åƒ")
    for i, (l, r) in enumerate(paired_images[:5]):
        print(f"  ç¤ºä¾‹å¯¹ {i+1}: {os.path.basename(l)} â†” {os.path.basename(r)}")
    if len(paired_images) > 5:
        print(f"  ... åŠ {len(paired_images)-5} å¯¹")
    
    return paired_images

def compute_epipolar_error(objpoints, imgpoints_left, imgpoints_right, 
                          mtx_left, dist_left, mtx_right, dist_right,
                          R1, R2, P1, P2):
    """
    è®¡ç®—æ ¡æ­£åçš„å¹³å‡æçº¿è¯¯å·® (åƒç´ )
    
    æçº¿è¯¯å·®è®¡ç®—åŸç†ï¼š
    1. ç«‹ä½“æ ¡æ­£åï¼Œå·¦å³å›¾åƒä¸­çš„å¯¹åº”ç‚¹åº”è¯¥ä½äºåŒä¸€æ°´å¹³çº¿ä¸Šï¼ˆyåæ ‡ç›¸åŒï¼‰
    2. å¯¹æ¯ä¸ªæ ‡å®šå›¾åƒå¯¹ï¼š
       - å°†å·¦å›¾è§’ç‚¹æŠ•å½±åˆ°æ ¡æ­£åçš„åæ ‡ç³»
       - å°†å³å›¾å¯¹åº”è§’ç‚¹æŠ•å½±åˆ°æ ¡æ­£åçš„åæ ‡ç³»
       - è®¡ç®—å¯¹åº”ç‚¹yåæ ‡çš„å·®å€¼ï¼šerror = |y_left - y_right|
    3. å¯¹æ‰€æœ‰å¯¹åº”ç‚¹çš„yåæ ‡å·®æ±‚å¹³å‡ï¼Œå¾—åˆ°å¹³å‡æçº¿è¯¯å·®
    
    è¯¯å·®è¶Šå°è¶Šå¥½ï¼š
    - < 0.5åƒç´ ï¼šä¼˜ç§€ï¼Œæçº¿å¯¹é½å®Œç¾
    - 0.5-1.0åƒç´ ï¼šè‰¯å¥½ï¼Œå¯ç”¨äºå¤§å¤šæ•°åº”ç”¨
    - > 1.0åƒç´ ï¼šéœ€æ”¹è¿›ï¼Œå¯èƒ½å½±å“ç«‹ä½“åŒ¹é…ç²¾åº¦
    """
    total_error = 0.0
    total_points = 0
    
    for i in range(len(objpoints)):
        # æ ¡æ­£å·¦å›¾ç‚¹ï¼šå°†åŸå§‹å›¾åƒåæ ‡è½¬æ¢ä¸ºæ ¡æ­£åçš„åæ ‡
        pts_left = imgpoints_left[i]
        pts_left_rect = cv2.undistortPoints(pts_left, mtx_left, dist_left, R=R1, P=P1)
        
        # æ ¡æ­£å³å›¾ç‚¹ï¼šå°†åŸå§‹å›¾åƒåæ ‡è½¬æ¢ä¸ºæ ¡æ­£åçš„åæ ‡
        pts_right = imgpoints_right[i]
        pts_right_rect = cv2.undistortPoints(pts_right, mtx_right, dist_right, R=R2, P=P2)
        
        # è®¡ç®—yåæ ‡å·® (æçº¿è¯¯å·®)
        # ç†æƒ³æƒ…å†µä¸‹ï¼Œæ ¡æ­£åå¯¹åº”ç‚¹çš„yåæ ‡åº”è¯¥å®Œå…¨ç›¸åŒ
        for j in range(len(pts_left_rect)):
            pt_l = pts_left_rect[j, 0]
            pt_r = pts_right_rect[j, 0]
            error = abs(pt_l[1] - pt_r[1])  # yåæ ‡å·®
            total_error += error
            total_points += 1
    
    mean_error = total_error / total_points if total_points > 0 else float('inf')
    return mean_error, total_points

def stereo_calibration(args):
    """ä¸»æ ‡å®šå‡½æ•°"""
    print("="*60)
    print("åŒç›®æ‘„åƒå¤´æ ‡å®šå·¥å…· - ä¸“ä¸šä¼˜åŒ–ç‰ˆ")
    print("="*60)
    
    # è§£ææ£‹ç›˜æ ¼å°ºå¯¸
    try:
        chessboard_size = tuple(map(int, args.size.split('x')))
        assert len(chessboard_size) == 2
    except:
        raise ValueError("æ— æ•ˆçš„æ£‹ç›˜æ ¼å°ºå¯¸! æ ¼å¼åº”ä¸º '9x6'")
    
    print(f"é…ç½®:")
    print(f"  æ£‹ç›˜æ ¼: {chessboard_size[0]}x{chessboard_size[1]} å†…è§’ç‚¹")
    print(f"  æ–¹æ ¼å°ºå¯¸: {args.square*1000:.1f} mm")
    print(f"  ç«‹ä½“æ ¡æ­£ alpha: {args.alpha:.2f} (0=è£å‰ªæœ€å¤§, 1=ä¿ç•™å…¨éƒ¨)")
    print(f"  è¾“å‡ºç›®å½•: '{args.output}'")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output, exist_ok=True)
    
    # é…å¯¹å›¾åƒ
    paired_images = pair_images(args.left, args.right)
    if len(paired_images) < 10:
        print(f"âš ï¸ è­¦å‘Š: ä»… {len(paired_images)} å¯¹å›¾åƒï¼Œå»ºè®®è‡³å°‘15å¯¹ä»¥è·å¾—æ›´å¥½ç²¾åº¦")
    
    # å‡†å¤‡å¯¹è±¡ç‚¹
    objp = np.zeros((chessboard_size[0] * chessboard_size[1], 3), np.float32)
    objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2)
    objp *= args.square  # è½¬æ¢ä¸ºç‰©ç†å•ä½(ç±³)
    
    # å­˜å‚¨ç‚¹
    objpoints = []  # 3Dç‚¹
    imgpoints_left = []  # å·¦ç›¸æœº2Dç‚¹
    imgpoints_right = []  # å³ç›¸æœº2Dç‚¹
    
    # å¤„ç†æ¯å¯¹å›¾åƒ
    print("\n" + "-"*50)
    print("æ£€æµ‹æ£‹ç›˜æ ¼è§’ç‚¹...")
    print("-"*50)
    
    valid_pairs = 0
    for idx, (left_path, right_path) in enumerate(paired_images):
        # è¯»å–å›¾åƒ
        img_left = cv2.imread(left_path)
        img_right = cv2.imread(right_path)
        
        if img_left is None or img_right is None:
            print(f"  è·³è¿‡å¯¹ {idx+1}: æ— æ³•è¯»å–å›¾åƒ ({left_path}, {right_path})")
            continue
        
        h, w = img_left.shape[:2]
        
        # è½¬ç°åº¦
        gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)
        gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)
        
        # æŸ¥æ‰¾è§’ç‚¹
        ret_left, corners_left = cv2.findChessboardCorners(
            gray_left, chessboard_size, 
            flags=cv2.CALIB_CB_ADAPTIVE_THRESH | 
                  cv2.CALIB_CB_FAST_CHECK | 
                  cv2.CALIB_CB_NORMALIZE_IMAGE
        )
        
        ret_right, corners_right = cv2.findChessboardCorners(
            gray_right, chessboard_size,
            flags=cv2.CALIB_CB_ADAPTIVE_THRESH | 
                  cv2.CALIB_CB_FAST_CHECK | 
                  cv2.CALIB_CB_NORMALIZE_IMAGE
        )
        
        # å¯è§†åŒ–
        display_left = img_left.copy()
        display_right = img_right.copy()
        cv2.drawChessboardCorners(display_left, chessboard_size, corners_left, ret_left)
        cv2.drawChessboardCorners(display_right, chessboard_size, corners_right, ret_right)
        
        # æ˜¾ç¤º
        combined = np.hstack((display_left, display_right))
        combined = put_text_cn(combined, f"å›¾åƒå¯¹: {idx+1}/{len(paired_images)}", (20, 30), (0, 255, 0), 28)
        
        if ret_left and ret_right:
            combined = put_text_cn(combined, "çŠ¶æ€: è§’ç‚¹æ£€æµ‹æˆåŠŸ", (20, 70), (0, 255, 0), 26)
        else:
            status = []
            if not ret_left: status.append("å·¦å›¾å¤±è´¥")
            if not ret_right: status.append("å³å›¾å¤±è´¥")
            combined = put_text_cn(combined, f"çŠ¶æ€: {' & '.join(status)}", (20, 70), (0, 0, 255), 26)
        
        cv2.imshow('è§’ç‚¹æ£€æµ‹ - æŒ‰ä»»æ„é”®ç»§ç»­', combined)
        key = cv2.waitKey(0) & 0xFF
        if key == 27:  # ESC
            print("ç”¨æˆ·ä¸­æ–­æ ‡å®šè¿‡ç¨‹")
            cv2.destroyAllWindows()
            return None
        
        # äºšåƒç´ ç²¾åŒ–
        if ret_left and ret_right:
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
            corners_left_refined = cv2.cornerSubPix(gray_left, corners_left, (11, 11), (-1, -1), criteria)
            corners_right_refined = cv2.cornerSubPix(gray_right, corners_right, (11, 11), (-1, -1), criteria)
            
            objpoints.append(objp)
            imgpoints_left.append(corners_left_refined)
            imgpoints_right.append(corners_right_refined)
            valid_pairs += 1
            
            print(f"  å¯¹ {idx+1}: æˆåŠŸæ£€æµ‹è§’ç‚¹ (ç´¯è®¡: {valid_pairs})")
        else:
            print(f"  å¯¹ {idx+1}: è§’ç‚¹æ£€æµ‹å¤±è´¥")
    
    cv2.destroyAllWindows()
    
    if valid_pairs < 5:
        print(f"âŒ é”™è¯¯: ä»… {valid_pairs} å¯¹æœ‰æ•ˆå›¾åƒï¼Œéœ€è¦è‡³å°‘5å¯¹")
        return None
    
    print(f"\nâœ… æˆåŠŸæ£€æµ‹ {valid_pairs} å¯¹å›¾åƒçš„è§’ç‚¹")
    
    # å•ç›®ä¼˜åŒ–æ ‡å¿—
    calib_flags = cv2.CALIB_RATIONAL_MODEL | cv2.CALIB_THIN_PRISM_MODEL
    
    # å·¦ç›¸æœºæ ‡å®š
    # å•ç›®RMSè¯¯å·®è®¡ç®—åŸç†ï¼š
    # 1. ä½¿ç”¨æ ‡å®šå¾—åˆ°çš„ç›¸æœºå†…å‚(K)å’Œç•¸å˜ç³»æ•°ï¼Œå°†3Dæ ‡å®šæ¿è§’ç‚¹æŠ•å½±å›2Då›¾åƒ
    # 2. è®¡ç®—æŠ•å½±ç‚¹ä¸æ£€æµ‹åˆ°çš„è§’ç‚¹ä¹‹é—´çš„æ¬§æ°è·ç¦»
    # 3. å¯¹æ‰€æœ‰ç‚¹æ±‚å‡æ–¹æ ¹(RMS)ï¼šRMS = sqrt(mean((x_proj - x_detected)^2 + (y_proj - y_detected)^2))
    # è¯¯å·®è¶Šå°è¶Šå¥½ï¼š<0.5åƒç´ =ä¼˜ç§€, 0.5-1.0åƒç´ =è‰¯å¥½, >1.0åƒç´ =éœ€æ”¹è¿›
    print("\n" + "-"*50)
    print("å·¦ç›¸æœºæ ‡å®š...")
    print("-"*50)
    ret_left, mtx_left, dist_left, rvecs_left, tvecs_left = cv2.calibrateCamera(
        objpoints, imgpoints_left, (w, h), None, None, flags=calib_flags)
    print(f"  é‡æŠ•å½±è¯¯å·® (RMS): {ret_left:.4f} åƒç´ ")
    
    # å³ç›¸æœºæ ‡å®š
    print("\n" + "-"*50)
    print("å³ç›¸æœºæ ‡å®š...")
    print("-"*50)
    ret_right, mtx_right, dist_right, rvecs_right, tvecs_right = cv2.calibrateCamera(
        objpoints, imgpoints_right, (w, h), None, None, flags=calib_flags)
    print(f"  é‡æŠ•å½±è¯¯å·® (RMS): {ret_right:.4f} åƒç´ ")
    
    # ç«‹ä½“æ ‡å®š
    # ç«‹ä½“RMSè¯¯å·®è®¡ç®—åŸç†ï¼š
    # 1. åŒæ—¶ä¼˜åŒ–å·¦å³ç›¸æœºçš„å†…å‚ã€å¤–å‚(R, T)å’Œç•¸å˜ç³»æ•°
    # 2. å°†3Dæ ‡å®šæ¿è§’ç‚¹åˆ†åˆ«æŠ•å½±åˆ°å·¦å³å›¾åƒ
    # 3. è®¡ç®—å·¦å³å›¾åƒæŠ•å½±ç‚¹ä¸æ£€æµ‹è§’ç‚¹çš„è¯¯å·®ï¼Œå¹¶è€ƒè™‘ç«‹ä½“å‡ ä½•çº¦æŸ
    # 4. å¯¹æ‰€æœ‰ç‚¹æ±‚å‡æ–¹æ ¹ï¼Œå¾—åˆ°ç«‹ä½“RMSè¯¯å·®
    # è¯¯å·®è¶Šå°è¶Šå¥½ï¼š<0.5åƒç´ =ä¼˜ç§€, 0.5-1.0åƒç´ =è‰¯å¥½, >1.0åƒç´ =éœ€æ”¹è¿›
    print("\n" + "-"*50)
    print("ç«‹ä½“æ ‡å®š...")
    print("-"*50)
    stereo_flags = cv2.CALIB_FIX_INTRINSIC | cv2.CALIB_USE_INTRINSIC_GUESS
    ret, mtx_left, dist_left, mtx_right, dist_right, R, T, E, F = cv2.stereoCalibrate(
        objpoints, imgpoints_left, imgpoints_right,
        mtx_left, dist_left, mtx_right, dist_right,
        (w, h), flags=stereo_flags,
        criteria=(cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)
    )
    print(f"  ç«‹ä½“é‡æŠ•å½±è¯¯å·® (RMS): {ret:.4f} åƒç´ ")
    
    # ç«‹ä½“æ ¡æ­£
    print("\n" + "-"*50)
    print("ç«‹ä½“æ ¡æ­£ä¼˜åŒ–...")
    print("-"*50)
    R1, R2, P1, P2, Q, validPixROI1, validPixROI2 = cv2.stereoRectify(
        mtx_left, dist_left, mtx_right, dist_right,
        (w, h), R, T,
        alpha=args.alpha,  # å…³é”®å‚æ•°!
        flags=cv2.CALIB_ZERO_DISPARITY
    )
    
    # è®¡ç®—æçº¿è¯¯å·®
    epi_error, total_points = compute_epipolar_error(
        objpoints, imgpoints_left, imgpoints_right,
        mtx_left, dist_left, mtx_right, dist_right,
        R1, R2, P1, P2
    )
    print(f"  å¹³å‡æçº¿è¯¯å·®: {epi_error:.4f} åƒç´  (åŸºäº {total_points} ä¸ªç‚¹)")
    
    # ç‰©ç†å‚æ•°éªŒè¯
    baseline = np.linalg.norm(T)
    fx_avg = (mtx_left[0,0] + mtx_right[0,0]) / 2
    fy_avg = (mtx_left[1,1] + mtx_right[1,1]) / 2
    min_depth = baseline * fx_avg / 200  # æœ€å¤§è§†å·®200åƒç´ 
    max_depth = baseline * fx_avg / 5    # æœ€å°è§†å·®5åƒç´ 
    
    print("\n" + "="*50)
    print("æ ‡å®šè´¨é‡è¯„ä¼°")
    print("="*50)
    print(f"ã€å‡ ä½•ç²¾åº¦ã€‘")
    print(f"  å·¦ç›¸æœº RMS è¯¯å·®: {ret_left:.4f} åƒç´  {'âœ…' if ret_left < 0.5 else 'âš ï¸' if ret_left < 1.0 else 'âŒ'}")
    print(f"  å³ç›¸æœº RMS è¯¯å·®: {ret_right:.4f} åƒç´  {'âœ…' if ret_right < 0.5 else 'âš ï¸' if ret_right < 1.0 else 'âŒ'}")
    print(f"  ç«‹ä½“ RMS è¯¯å·®: {ret:.4f} åƒç´ (0.5ä»¥å†…å¯æ¥å—) {'âœ…' if ret < 0.5 else 'âš ï¸' if ret < 1.0 else 'âŒ'}")
    print(f"  æçº¿è¯¯å·®: {epi_error:.4f} åƒç´ (1ä»¥å†…å¯æ¥å—) {'âœ… ä¼˜ç§€' if epi_error < 0.5 else 'âš ï¸ è‰¯å¥½' if epi_error < 1.0 else 'âŒ éœ€æ”¹è¿›'}")
    
    print(f"\nã€ç‰©ç†å‚æ•°ã€‘")
    print(f"  åŸºçº¿é•¿åº¦: {baseline:.4f} ç±³ {'âœ… åˆç†' if 0.05 < baseline < 0.3 else 'âš ï¸ éªŒè¯'}")
    print(f"  å·¦ç„¦è·: {mtx_left[0,0]:.1f} åƒç´ , å³ç„¦è·: {mtx_right[0,0]:.1f} åƒç´  (å·®å¼‚: {abs(mtx_left[0,0]-mtx_right[0,0])/fx_avg:.1%})")
    print(f"  æœ‰æ•ˆæ·±åº¦èŒƒå›´: {min_depth:.2f}m - {max_depth:.2f}m")
    print(f"  ç¯®çƒç»•æ†é€‚ç”¨æ€§: {'âœ… é€‚ç”¨' if (1.0 < min_depth < 2.0 and max_depth > 3.0) else 'âš ï¸ éƒ¨åˆ†é€‚ç”¨' if max_depth > 2.5 else 'âŒ ä¸é€‚ç”¨'}")
    
    print(f"\nã€æœ‰æ•ˆåŒºåŸŸã€‘")
    print(f"  å·¦ç›¸æœºæœ‰æ•ˆåŒºåŸŸ: {validPixROI1}")
    print(f"  å³ç›¸æœºæœ‰æ•ˆåŒºåŸŸ: {validPixROI2}")
    
    # ä¿å­˜ç»“æœ
    output_xml = os.path.join(args.output, 'stereo_calibration.xml')
    output_yaml = os.path.join(args.output, 'stereo_calibration.yaml')
    output_vis = os.path.join(args.output, 'rectification_visualization.jpg')
    
    # ä¿å­˜XML (OpenCVæ ‡å‡†æ ¼å¼)
    fs = cv2.FileStorage(output_xml, cv2.FILE_STORAGE_WRITE)
    fs.write("cameraMatrix1", mtx_left)
    fs.write("distCoeffs1", dist_left)
    fs.write("cameraMatrix2", mtx_right)
    fs.write("distCoeffs2", dist_right)
    fs.write("R", R)
    fs.write("T", T)
    fs.write("E", E)
    fs.write("F", F)
    fs.write("R1", R1)
    fs.write("R2", R2)
    fs.write("P1", P1)
    fs.write("P2", P2)
    fs.write("Q", Q)
    fs.write("image_width", w)
    fs.write("image_height", h)
    fs.write("rms_error", ret)
    fs.write("epipolar_error", epi_error)
    fs.write("baseline", baseline)
    fs.write("validPixROI1", np.array(validPixROI1))
    fs.write("validPixROI2", np.array(validPixROI2))
    fs.release()
    
    # ä¿å­˜YAML (äººç±»å¯è¯»)
    calibration_data = {
        'calibration_date': str(datetime.now()),
        'image_size': {'width': w, 'height': h},
        'chessboard': {
            'size': [chessboard_size[0], chessboard_size[1]],
            'square_size_m': args.square
        },
        'reprojection_error': {
            'rms': float(ret),
            'left_camera': float(ret_left),
            'right_camera': float(ret_right)
        },
        'epipolar_error': float(epi_error),
        'baseline_m': float(baseline),
        'camera_matrix_left': mtx_left.tolist(),
        'distortion_coeffs_left': dist_left.ravel().tolist(),
        'camera_matrix_right': mtx_right.tolist(),
        'distortion_coeffs_right': dist_right.ravel().tolist(),
        'rotation_matrix': R.tolist(),
        'translation_vector': T.ravel().tolist(),
        'rectification': {
            'alpha': args.alpha,
            'valid_roi_left': validPixROI1,
            'valid_roi_right': validPixROI2
        },
        'depth_range_m': [float(min_depth), float(max_depth)]
    }
    
    with open(output_yaml, 'w') as f:
        yaml.dump(calibration_data, f, default_flow_style=False)
    
    print(f"\nâœ… æ ‡å®šç»“æœå·²ä¿å­˜:")
    print(f"  - OpenCVæ ‡å‡†æ ¼å¼: {output_xml}")
    print(f"  - äººç±»å¯è¯»æ ¼å¼: {output_yaml}")
    
    # å¯è§†åŒ–æ ¡æ­£æ•ˆæœ
    if paired_images:
        visualize_rectification(paired_images[0], mtx_left, dist_left, mtx_right, dist_right, 
                               R1, R2, P1, P2, args.output, validPixROI1, validPixROI2)
    
    print(f"\n{'='*60}")
    if epi_error < 0.5 and ret < 0.5:
        print("ğŸ‰ æ ‡å®šæˆåŠŸ! ç»“æœè´¨é‡ä¼˜ç§€ï¼Œé€‚ç”¨äºç¯®çƒç»•æ†åœºæ™¯")
    elif epi_error < 1.0 and ret < 1.0:
        print("ğŸ‘ æ ‡å®šæˆåŠŸ! ç»“æœè´¨é‡è‰¯å¥½ï¼Œå¯ç”¨äºç¯®çƒç»•æ†ï¼Œä½†è¾¹ç¼˜ç²¾åº¦ç•¥ä½")
    else:
        print("âš ï¸ æ ‡å®šå®Œæˆï¼Œä½†è´¨é‡ä¸è¶³! å»ºè®®:")
        print("   - å¢åŠ æ›´å¤šå›¾åƒ (ç‰¹åˆ«æ˜¯è¾¹ç¼˜åŒºåŸŸ)")
        print("   - æ£€æŸ¥æ ‡å®šæ¿æ˜¯å¦å¹³æ•´")
        print(f"   - è°ƒæ•´alphaå‚æ•° (å½“å‰:{args.alpha})")
    
    return {
        'mtx_left': mtx_left,
        'dist_left': dist_left,
        'mtx_right': mtx_right,
        'dist_right': dist_right,
        'R': R,
        'T': T,
        'R1': R1,
        'R2': R2,
        'P1': P1,
        'P2': P2,
        'Q': Q,
        'epi_error': epi_error,
        'baseline': baseline
    }

def visualize_rectification(first_pair, mtx_left, dist_left, mtx_right, dist_right,
                          R1, R2, P1, P2, output_dir, roi1, roi2):
    """å¯è§†åŒ–ç«‹ä½“æ ¡æ­£æ•ˆæœ"""
    print("\n" + "-"*50)
    print("ç”Ÿæˆæ ¡æ­£æ•ˆæœå¯è§†åŒ–...")
    print("-"*50)
    
    left_path, right_path = first_pair
    img_left = cv2.imread(left_path)
    img_right = cv2.imread(right_path)
    
    if img_left is None or img_right is None:
        print("  è­¦å‘Š: æ— æ³•è¯»å–æµ‹è¯•å›¾åƒï¼Œè·³è¿‡å¯è§†åŒ–")
        return
    
    h, w = img_left.shape[:2]
    
    # è®¡ç®—æ ¡æ­£æ˜ å°„
    map1_left, map2_left = cv2.initUndistortRectifyMap(
        mtx_left, dist_left, R1, P1, (w, h), cv2.CV_16SC2)
    map1_right, map2_right = cv2.initUndistortRectifyMap(
        mtx_right, dist_right, R2, P2, (w, h), cv2.CV_16SC2)
    
    # åº”ç”¨æ ¡æ­£
    img_left_rect = cv2.remap(img_left, map1_left, map2_left, cv2.INTER_LANCZOS4)
    img_right_rect = cv2.remap(img_right, map1_right, map2_right, cv2.INTER_LANCZOS4)
    
    # ç»˜åˆ¶æ°´å¹³çº¿
    line_img_left = img_left_rect.copy()
    line_img_right = img_right_rect.copy()
    for y in range(50, h, 50):
        cv2.line(line_img_left, (0, y), (w, y), (0, 255, 0), 1)
        cv2.line(line_img_right, (0, y), (w, y), (0, 255, 0), 1)
    
    # æ ‡è®°æœ‰æ•ˆåŒºåŸŸ
    if roi1[2] > 0 and roi1[3] > 0:
        cv2.rectangle(line_img_left, (roi1[0], roi1[1]), (roi1[0]+roi1[2], roi1[1]+roi1[3]), (0, 0, 255), 2)
    if roi2[2] > 0 and roi2[3] > 0:
        cv2.rectangle(line_img_right, (roi2[0], roi2[1]), (roi2[0]+roi2[2], roi2[1]+roi2[3]), (0, 0, 255), 2)
    
    # æ‹¼æ¥ç»“æœ
    top_row = np.hstack((img_left, img_right))
    bottom_row = np.hstack((line_img_left, line_img_right))
    result = np.vstack((top_row, bottom_row))
    
    # æ·»åŠ æ ‡æ³¨
    result = put_text_cn(result, "åŸå§‹å›¾åƒ", (50, 20), (255, 255, 255), 28)
    result = put_text_cn(result, "æ ¡æ­£åå›¾åƒ + æ°´å¹³çº¿", (w + 50, 20 + h), (255, 255, 255), 28)
    result = put_text_cn(result, "æœ‰æ•ˆåŒºåŸŸ", (50, h-30), (0, 0, 255), 24)
    
    # ä¿å­˜
    output_path = os.path.join(output_dir, 'rectification_visualization.jpg')
    cv2.imwrite(output_path, result)
    print(f"  âœ… å¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_path}")
    
    # æ˜¾ç¤º
    cv2.imshow('ç«‹ä½“æ ¡æ­£æ•ˆæœ (æŒ‰ä»»æ„é”®å…³é—­)', result)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def test_rectification(calib_data, test_left, test_right, output_dir):
    """æµ‹è¯•æ ¡æ­£æ•ˆæœ"""
    print("\n" + "="*60)
    print("ç«‹ä½“æ ¡æ­£æ•ˆæœæµ‹è¯•")
    print("="*60)
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    img_left = cv2.imread(test_left)
    img_right = cv2.imread(test_right)
    
    if img_left is None or img_right is None:
        print(f"âŒ æ— æ³•è¯»å–æµ‹è¯•å›¾åƒ: {test_left}, {test_right}")
        return
    
    h, w = img_left.shape[:2]
    
    # è®¡ç®—æ ¡æ­£æ˜ å°„
    map1_left, map2_left = cv2.initUndistortRectifyMap(
        calib_data['mtx_left'], calib_data['dist_left'], 
        calib_data['R1'], calib_data['P1'], (w, h), cv2.CV_16SC2)
    map1_right, map2_right = cv2.initUndistortRectifyMap(
        calib_data['mtx_right'], calib_data['dist_right'], 
        calib_data['R2'], calib_data['P2'], (w, h), cv2.CV_16SC2)
    
    # åº”ç”¨æ ¡æ­£
    img_left_rect = cv2.remap(img_left, map1_left, map2_left, cv2.INTER_LANCZOS4)
    img_right_rect = cv2.remap(img_right, map1_right, map2_right, cv2.INTER_LANCZOS4)
    
    # æ˜¾ç¤º
    combined = np.hstack((img_left_rect, img_right_rect))
    cv2.putText(combined, "å·¦ç›¸æœºæ ¡æ­£å", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.putText(combined, "å³ç›¸æœºæ ¡æ­£å", (w + 50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    cv2.imshow('æ ¡æ­£æ•ˆæœæµ‹è¯• - æŒ‰ä»»æ„é”®ä¿å­˜', combined)
    cv2.waitKey(0)
    
    # ä¿å­˜
    output_path = os.path.join(output_dir, 'test_rectification.jpg')
    cv2.imwrite(output_path, combined)
    print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    cv2.destroyAllWindows()

if __name__ == "__main__":
    args = parse_args()
    
    # è¿è¡Œæ ‡å®š
    calib_data = stereo_calibration(args)
    
    if calib_data is None:
        exit(1)
    
    # æµ‹è¯•æ ¡æ­£
    if args.test and hasattr(args, 'test_left') and hasattr(args, 'test_right'):
        test_rectification(calib_data, args.test_left, args.test_right, args.output)
    
    print("\n" + "="*60)
    print("æ ‡å®šæµç¨‹å®Œæˆ!")
    print("="*60)
